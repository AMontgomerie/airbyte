# S3

## Overview

This destination writes data to S3 bucket.

The Airbyte S3 destination allows you to sync data to AWS S3. Each stream is written to its own directory under the bucket.

## Sync Mode

| Feature | Support | Notes |
| :--- | :---: | :--- |
| Full Refresh Sync | ✅ | Warning. This mode deletes all previously synced data. |
| Incremental - Append Sync | ✅ | |
| Namespaces | ❌ | Setting a specific bucket path is equivalent to having separate namespaces. |

## Configuration

| Parameter | Type | Notes |
| :--- | :---: | :--- |
| S3 Bucket Name | string | |
| S3 Bucket Path | string | Subdirectory under a bucket. |
| S3 Region | string | See [here](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions) for all region codes. |
| Access Key ID | string | AWS credential. |
| Secret Access Key | string | AWS credential. |
| Part Size | int | Size of each file part in MBs. |
| Format | object | Format specific configuration. See below for details. |

## Output Schema

Currently, this connector only writes data as CSV files. More formats (e.g. Apache Parquet) will be supported in the future.

### CSV

| Format Config | Type | Notes |
| :--- | :---: | :--- |
| Flattening | enum | Either no flattening, or root level flattening. |

For example, given the following json data from a source:

```json
{
  "user_id": 123,
  "name": {
    "first": "John",
    "last": "Doe"
  }
}
```

With no flattening, the output CSV will be:

| `_airbyte_ab_id` | `_airbyte_emitted_at` | `_airbyte_data` |
| :--- | :--- | :--- |
| `26d73cde-7eb1-4e1e-b7db-a4c03b4cf206` | 1622135805000 | `{ "user_id":123, "name": { "first": "John", "last": "Doe" } }` |

With root level flattening, the output CSV will be:

| `_airbyte_ab_id` | `_airbyte_emitted_at` | `user_id` | `name` |
| :--- | :--- | :--- | :--- |
| `26d73cde-7eb1-4e1e-b7db-a4c03b4cf206` | 1622135805000 | 123 | `{ "first": "John", "last": "Doe" }` |
